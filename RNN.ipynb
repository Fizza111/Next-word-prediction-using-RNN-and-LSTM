{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZpmM21CxDJGTyK94oDSCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fizza111/Next-word-prediction-using-RNN-and-LSTM/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "assdwGd2U5el"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[\n",
        "     \"Machine learning is transforming how we interact with technology every day.\"\n",
        "     \"Algorithms learn from data to make predictions or decisions.\"\n",
        "     \"Supervised learning teaches models using labeled examples.\"\n",
        "     \"Unsupervised learning uncovers hidden patterns in data without labels.\"\n",
        "     \"Reinforcement learning mimics reward-based behavior like training a pet.\"\n",
        "     \"The more data, the better the model usually performs.\"\n",
        "     \"Neural networks mimic the way human brains process information.\"\n",
        "     \"Feature engineering is the art of selecting relevant input variables.\"\n",
        "     \"Bias in training data can lead to unfair predictions.\"\n",
        "     \"Machine learning powers everything from spam filters to self-driving cars.\"\n",
        "     \"Overfitting happens when a model learns noise instead of signal.\"\n",
        "     \"Underfitting means the model isn’t learning enough from the data.\"\n",
        "     \"Training data is the foundation of any machine learning model.\"\n",
        "     \"Hyperparameters control how a model learns.\"\n",
        "     \"Classification assigns categories, while regression predicts values.\"\n",
        "     \"Data preprocessing cleans and transforms raw data for modeling.\"\n",
        "     \"Cross-validation helps evaluate model performance reliably.\"\n",
        "     \"Gradient descent helps optimize the model's accuracy.\"\n",
        "     \"Decision trees are easy to understand but prone to overfitting.\"\n",
        "     \"Support vector machines find the optimal boundary between classes.\"\n",
        "     \"Deep learning leverages multiple layers of abstraction.\"\n",
        "     \"Machine learning models can improve over time with new data.\"\n",
        "     \"Label imbalance can skew prediction results.\"\n",
        "     \"Scikit-learn is a popular Python library for ML.\"\n",
        "     \"TensorFlow and PyTorch are widely used for deep learning.\"\n",
        "     \"Model accuracy isn’t always enough; interpretability matters too.\"\n",
        "     \"AI applications often use machine learning at their core.\"\n",
        "     \"Linear regression is one of the simplest ML techniques.\"\n",
        "     \"Clustering groups similar data points together.\"\n",
        "     \"K-means is a popular clustering algorithm.\"\n",
        "     \"Ensemble methods combine predictions from multiple models.\"\n",
        "     \"Random Forest is a type of ensemble method using decision trees.\"\n",
        "     \"A confusion matrix helps visualize classification performance.\"\n",
        "     \"Precision and recall balance correctness and completeness.\"\n",
        "     \"F1 score provides a single metric for classification trade-offs.\"\n",
        "     \"Machine learning is reshaping medicine, finance, and retail.\"\n",
        "     \"Predictive modeling enables proactive decision-making.\"\n",
        "     \"Anomaly detection spots unusual data points.\"\n",
        "     \"Sentiment analysis can reveal customer opinions automatically.\"\n",
        "     \"Spam filters use machine learning to sort unwanted emails.\"\n",
        "     \"Image recognition is driven by convolutional neural networks.\"\n",
        "     \"Transfer learning reuses knowledge from previous models.\"\n",
        "     \"ML models need fine-tuning to reach optimal performance.\"\n",
        "     \"Ethical use of machine learning is a growing concern.\"\n",
        "     \"Explainable AI helps build trust in model predictions.\"\n",
        "     \"Automated ML tools simplify the training process.\"\n",
        "     \"Time series models forecast trends and patterns over time.\"\n",
        "     \"Data labeling can be expensive and time-consuming.\"\n",
        "     \"Machine learning is evolving rapidly with new innovations.\"\n",
        "     \"Training a model can take minutes or weeks, depending on complexity.\"\n",
        "     \"Model deployment brings ML models to real-world applications.\"\n",
        "     \"Streaming data requires online learning methods.\"\n",
        "     \"Feature selection reduces dimensionality and noise.\"\n",
        "     \"Dimensionality reduction simplifies data without losing insights.\"\n",
        "     \"Principal Component Analysis is a technique for reducing data dimensions.\"\n",
        "     \"Machine learning thrives in environments rich in feedback.\"\n",
        "     \"Computational power is critical for training complex models.\"\n",
        "     \"GPU acceleration speeds up deep learning tasks.\"\n",
        "     \"Hyperparameter tuning boosts model performance.\"\n",
        "     \"Automated pipelines help streamline ML workflows.\"\n",
        "     \"Data visualization helps interpret model outputs.\"\n",
        "     \"Categorical variables often require encoding techniques.\"\n",
        "     \"Normalization makes features comparable across scales.\"\n",
        "     \"Overlapping classes complicate classification problems.\"\n",
        "     \"Natural Language Processing is powered by machine learning.\"\n",
        "      \"Data augmentation improves model generalization.\"\n",
        "      \"Reproducibility in ML ensures consistent results.\"\n",
        "      \"Machine learning models must be monitored after deployment.\"\n",
        "      \"Model drift occurs when data changes over time.\"\n",
        "      \"Online learning adapts to incoming data in real time.\"\n",
        "      \"Cloud platforms offer scalable ML training environments.\"\n",
        "      \"Real-time prediction is critical in applications like fraud detection.\"\n",
        "      \"Reinforcement learning can outperform humans in games.\"\n",
        "      \"ML models often require continuous evaluation.\"\n",
        "      \"Algorithms vary widely in complexity and purpose.\"\n",
        "      \"Training data should reflect the problem space accurately.\"\n",
        "      \"Bias-variance tradeoff affects model generalization.\"\n",
        "      \"Bagging and boosting are techniques to improve accuracy.\"\n",
        "      \"Model checkpoints save training progress.\"\n",
        "      \"Early stopping prevents overfitting during training.\"\n",
        "      \"Loss functions quantify prediction errors.\"\n",
        "      \"Optimization algorithms search for the best model parameters.\"\n",
        "      \"Ethical datasets avoid reinforcing harmful stereotypes.\"\n",
        "      \"Human oversight in ML helps maintain responsibility.\"\n",
        "      \"Neural architecture search automates model design.\"\n",
        "      \"Machine learning enhances recommendation systems.\"\n",
        "      \"Dynamic pricing uses ML to adjust prices on demand.\"\n",
        "      \"Voice assistants rely on machine learning for understanding speech.\"\n",
        "      \"Facial recognition uses deep learning to identify individuals.\"\n",
        "      \"Generative models can create realistic images and sounds.\"\n",
        "      \"Machine learning isn’t magic—it’s mathematics at scale.\"\n",
        "      \"Collaborative filtering predicts user preferences.\"\n",
        "      \"Data scientists work closely with ML models.\"\n",
        "      \"ML-based robotics can adapt to changing environments.\"\n",
        "      \"Health diagnostics benefit from intelligent predictions.\"\n",
        "      \"Fraud detection systems rely heavily on ML signals.\"\n",
        "      \"Self-driving cars constantly learn from their surroundings.\"\n",
        "      \"Personalization engines recommend content or products.\"\n",
        "      \"Social media feeds are shaped by ML algorithms.\"\n",
        "      \"Human-in-the-loop approaches combine ML and expert input.\"\n",
        "      \"Zero-shot learning makes predictions on unseen categories.\"\n",
        "      \"Few-shot learning trains with very little labeled data.\"\n",
        "      \"Active learning queries the user for uncertain cases.\"\n",
        "      \"Meta-learning teaches models how to learn better.\"\n",
        "      \"Machine learning is the heartbeat of modern AI systems.\"\n",
        "      \"With data and algorithms, machine learning unlocks new frontiers.\"\n",
        "]"
      ],
      "metadata": {
        "id": "pJsf3SuqVEJq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "total_words=len(tokenizer.word_index) + 1\n",
        "print(total_words)\n",
        "print(tokenizer.word_index)\n",
        "input_sequences=[]\n",
        "for line in sentences:\n",
        "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1,len(token_list)):\n",
        "        n_gram_sequences=token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequences)\n",
        "max_sequence_length=max([len(x) for x in input_sequences])\n",
        "input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_sequence_length,padding=\"pre\"))\n",
        "print(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZyZ99_vVEwS",
        "outputId": "d38d6b11-4382-461c-afa6-a834e1b3c5b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "447\n",
            "{'learning': 1, 'data': 2, 'model': 3, 'machine': 4, 'the': 5, 'is': 6, 'ml': 7, 'to': 8, 'models': 9, 'and': 10, 'in': 11, 'a': 12, 'training': 13, 'can': 14, 'for': 15, 'of': 16, 'from': 17, 'time': 18, 'with': 19, 'predictions': 20, 'helps': 21, 'algorithms': 22, 'on': 23, 'learn': 24, 'classification': 25, 'performance': 26, 'are': 27, 'deep': 28, 'how': 29, 'or': 30, 'neural': 31, 'human': 32, 'overfitting': 33, 'isn’t': 34, 'accuracy': 35, 'decision': 36, 'over': 37, 'new': 38, 'prediction': 39, 'ai': 40, 'applications': 41, 'often': 42, 'use': 43, 'techniques': 44, 'detection': 45, 'by': 46, 'real': 47, 'environments': 48, 'systems': 49, 'teaches': 50, 'using': 51, 'labeled': 52, 'patterns': 53, 'without': 54, 'reinforcement': 55, 'based': 56, 'like': 57, 'better': 58, 'networks': 59, 'process': 60, 'feature': 61, 'input': 62, 'variables': 63, 'bias': 64, 'spam': 65, 'filters': 66, 'self': 67, 'driving': 68, 'cars': 69, 'when': 70, 'learns': 71, 'noise': 72, 'means': 73, 'enough': 74, 'categories': 75, 'regression': 76, 'predicts': 77, 'modeling': 78, 'trees': 79, 'optimal': 80, 'classes': 81, 'multiple': 82, 'improve': 83, 'results': 84, 'popular': 85, 'widely': 86, 'at': 87, 'their': 88, 'clustering': 89, 'points': 90, 'ensemble': 91, 'methods': 92, 'combine': 93, 'analysis': 94, 'recognition': 95, 'tuning': 96, 'ethical': 97, 'automated': 98, 'be': 99, 'complexity': 100, 'deployment': 101, 'online': 102, 'dimensionality': 103, 'critical': 104, 'require': 105, 'makes': 106, 'generalization': 107, 'fraud': 108, 'search': 109, 'uses': 110, 'rely': 111, 'user': 112, 'shot': 113, 'transforming': 114, 'we': 115, 'interact': 116, 'technology': 117, 'every': 118, 'day': 119, 'make': 120, 'decisions': 121, 'supervised': 122, 'examples': 123, 'unsupervised': 124, 'uncovers': 125, 'hidden': 126, 'labels': 127, 'mimics': 128, 'reward': 129, 'behavior': 130, 'pet': 131, 'more': 132, 'usually': 133, 'performs': 134, 'mimic': 135, 'way': 136, 'brains': 137, 'information': 138, 'engineering': 139, 'art': 140, 'selecting': 141, 'relevant': 142, 'lead': 143, 'unfair': 144, 'powers': 145, 'everything': 146, 'happens': 147, 'instead': 148, 'signal': 149, 'underfitting': 150, 'foundation': 151, 'any': 152, 'hyperparameters': 153, 'control': 154, 'assigns': 155, 'while': 156, 'values': 157, 'preprocessing': 158, 'cleans': 159, 'transforms': 160, 'raw': 161, 'cross': 162, 'validation': 163, 'evaluate': 164, 'reliably': 165, 'gradient': 166, 'descent': 167, 'optimize': 168, \"model's\": 169, 'easy': 170, 'understand': 171, 'but': 172, 'prone': 173, 'support': 174, 'vector': 175, 'machines': 176, 'find': 177, 'boundary': 178, 'between': 179, 'leverages': 180, 'layers': 181, 'abstraction': 182, 'label': 183, 'imbalance': 184, 'skew': 185, 'scikit': 186, 'python': 187, 'library': 188, 'tensorflow': 189, 'pytorch': 190, 'used': 191, 'always': 192, 'interpretability': 193, 'matters': 194, 'too': 195, 'core': 196, 'linear': 197, 'one': 198, 'simplest': 199, 'groups': 200, 'similar': 201, 'together': 202, 'k': 203, 'algorithm': 204, 'random': 205, 'forest': 206, 'type': 207, 'method': 208, 'confusion': 209, 'matrix': 210, 'visualize': 211, 'precision': 212, 'recall': 213, 'balance': 214, 'correctness': 215, 'completeness': 216, 'f1': 217, 'score': 218, 'provides': 219, 'single': 220, 'metric': 221, 'trade': 222, 'offs': 223, 'reshaping': 224, 'medicine': 225, 'finance': 226, 'retail': 227, 'predictive': 228, 'enables': 229, 'proactive': 230, 'making': 231, 'anomaly': 232, 'spots': 233, 'unusual': 234, 'sentiment': 235, 'reveal': 236, 'customer': 237, 'opinions': 238, 'automatically': 239, 'sort': 240, 'unwanted': 241, 'emails': 242, 'image': 243, 'driven': 244, 'convolutional': 245, 'transfer': 246, 'reuses': 247, 'knowledge': 248, 'previous': 249, 'need': 250, 'fine': 251, 'reach': 252, 'growing': 253, 'concern': 254, 'explainable': 255, 'build': 256, 'trust': 257, 'tools': 258, 'simplify': 259, 'series': 260, 'forecast': 261, 'trends': 262, 'labeling': 263, 'expensive': 264, 'consuming': 265, 'evolving': 266, 'rapidly': 267, 'innovations': 268, 'take': 269, 'minutes': 270, 'weeks': 271, 'depending': 272, 'brings': 273, 'world': 274, 'streaming': 275, 'requires': 276, 'selection': 277, 'reduces': 278, 'reduction': 279, 'simplifies': 280, 'losing': 281, 'insights': 282, 'principal': 283, 'component': 284, 'technique': 285, 'reducing': 286, 'dimensions': 287, 'thrives': 288, 'rich': 289, 'feedback': 290, 'computational': 291, 'power': 292, 'complex': 293, 'gpu': 294, 'acceleration': 295, 'speeds': 296, 'up': 297, 'tasks': 298, 'hyperparameter': 299, 'boosts': 300, 'pipelines': 301, 'help': 302, 'streamline': 303, 'workflows': 304, 'visualization': 305, 'interpret': 306, 'outputs': 307, 'categorical': 308, 'encoding': 309, 'normalization': 310, 'features': 311, 'comparable': 312, 'across': 313, 'scales': 314, 'overlapping': 315, 'complicate': 316, 'problems': 317, 'natural': 318, 'language': 319, 'processing': 320, 'powered': 321, 'augmentation': 322, 'improves': 323, 'reproducibility': 324, 'ensures': 325, 'consistent': 326, 'must': 327, 'monitored': 328, 'after': 329, 'drift': 330, 'occurs': 331, 'changes': 332, 'adapts': 333, 'incoming': 334, 'cloud': 335, 'platforms': 336, 'offer': 337, 'scalable': 338, 'outperform': 339, 'humans': 340, 'games': 341, 'continuous': 342, 'evaluation': 343, 'vary': 344, 'purpose': 345, 'should': 346, 'reflect': 347, 'problem': 348, 'space': 349, 'accurately': 350, 'variance': 351, 'tradeoff': 352, 'affects': 353, 'bagging': 354, 'boosting': 355, 'checkpoints': 356, 'save': 357, 'progress': 358, 'early': 359, 'stopping': 360, 'prevents': 361, 'during': 362, 'loss': 363, 'functions': 364, 'quantify': 365, 'errors': 366, 'optimization': 367, 'best': 368, 'parameters': 369, 'datasets': 370, 'avoid': 371, 'reinforcing': 372, 'harmful': 373, 'stereotypes': 374, 'oversight': 375, 'maintain': 376, 'responsibility': 377, 'architecture': 378, 'automates': 379, 'design': 380, 'enhances': 381, 'recommendation': 382, 'dynamic': 383, 'pricing': 384, 'adjust': 385, 'prices': 386, 'demand': 387, 'voice': 388, 'assistants': 389, 'understanding': 390, 'speech': 391, 'facial': 392, 'identify': 393, 'individuals': 394, 'generative': 395, 'create': 396, 'realistic': 397, 'images': 398, 'sounds': 399, 'magic—it’s': 400, 'mathematics': 401, 'scale': 402, 'collaborative': 403, 'filtering': 404, 'preferences': 405, 'scientists': 406, 'work': 407, 'closely': 408, 'robotics': 409, 'adapt': 410, 'changing': 411, 'health': 412, 'diagnostics': 413, 'benefit': 414, 'intelligent': 415, 'heavily': 416, 'signals': 417, 'constantly': 418, 'surroundings': 419, 'personalization': 420, 'engines': 421, 'recommend': 422, 'content': 423, 'products': 424, 'social': 425, 'media': 426, 'feeds': 427, 'shaped': 428, 'loop': 429, 'approaches': 430, 'expert': 431, 'zero': 432, 'unseen': 433, 'few': 434, 'trains': 435, 'very': 436, 'little': 437, 'active': 438, 'queries': 439, 'uncertain': 440, 'cases': 441, 'meta': 442, 'heartbeat': 443, 'modern': 444, 'unlocks': 445, 'frontiers': 446}\n",
            "[[  0   0   0 ...   0   4   1]\n",
            " [  0   0   0 ...   4   1   6]\n",
            " [  0   0   0 ...   1   6 114]\n",
            " ...\n",
            " [  0   0   4 ...   4   1 445]\n",
            " [  0   4   1 ...   1 445  38]\n",
            " [  4   1   6 ... 445  38 446]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into input and labels\n",
        "X=input_sequences[:, :-1]\n",
        "print(\"input data :\",X)\n",
        "y=input_sequences[: ,-1]\n",
        "y=tf.keras.utils.to_categorical(y,num_classes=total_words)\n",
        "#Structurs of RNN model\n",
        "model=Sequential([\n",
        "    Embedding(total_words,10,input_length=max_sequence_length-1),\n",
        "    SimpleRNN(100),\n",
        "    Dense(total_words,activation=\"softmax\")\n",
        "\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJUojfr-VEy0",
        "outputId": "005be285-cc40-4303-8088-cebe68224044"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input data : [[  0   0   0 ...   0   0   4]\n",
            " [  0   0   0 ...   0   4   1]\n",
            " [  0   0   0 ...   4   1   6]\n",
            " ...\n",
            " [  0   0   4 ...  22   4   1]\n",
            " [  0   4   1 ...   4   1 445]\n",
            " [  4   1   6 ...   1 445  38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Lsa5uaF8VE1S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=70,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hppIIkI5VE4C",
        "outputId": "d432f305-3dbf-479c-920f-6051bdd6cfcd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.0014 - loss: 6.1067\n",
            "Epoch 2/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0049 - loss: 6.0846\n",
            "Epoch 3/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0256 - loss: 5.9225\n",
            "Epoch 4/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0357 - loss: 5.6726\n",
            "Epoch 5/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.0310 - loss: 5.6376\n",
            "Epoch 6/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0408 - loss: 5.6096\n",
            "Epoch 7/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0379 - loss: 5.6003\n",
            "Epoch 8/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0421 - loss: 5.6292\n",
            "Epoch 9/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0331 - loss: 5.5814\n",
            "Epoch 10/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.0354 - loss: 5.4971\n",
            "Epoch 11/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0406 - loss: 5.5942\n",
            "Epoch 12/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0398 - loss: 5.5539\n",
            "Epoch 13/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0335 - loss: 5.4862\n",
            "Epoch 14/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0277 - loss: 5.4770\n",
            "Epoch 15/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0524 - loss: 5.3305\n",
            "Epoch 16/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.0528 - loss: 5.2339\n",
            "Epoch 17/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0541 - loss: 5.2028\n",
            "Epoch 18/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0667 - loss: 5.0211\n",
            "Epoch 19/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0675 - loss: 4.8493\n",
            "Epoch 20/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.1073 - loss: 4.7062\n",
            "Epoch 21/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.1152 - loss: 4.5416\n",
            "Epoch 22/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.1067 - loss: 4.4572\n",
            "Epoch 23/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.1426 - loss: 4.2892\n",
            "Epoch 24/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.2554 - loss: 3.9749\n",
            "Epoch 25/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.2147 - loss: 3.9879\n",
            "Epoch 26/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3000 - loss: 3.8076\n",
            "Epoch 27/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.2952 - loss: 3.5774\n",
            "Epoch 28/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.3942 - loss: 3.3336\n",
            "Epoch 29/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.4821 - loss: 3.1926\n",
            "Epoch 30/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.5235 - loss: 2.9990\n",
            "Epoch 31/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.5612 - loss: 2.7811\n",
            "Epoch 32/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6009 - loss: 2.6358\n",
            "Epoch 33/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6382 - loss: 2.4328\n",
            "Epoch 34/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6625 - loss: 2.3468\n",
            "Epoch 35/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6904 - loss: 2.2295\n",
            "Epoch 36/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7326 - loss: 2.0894\n",
            "Epoch 37/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.7948 - loss: 1.8716\n",
            "Epoch 38/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8186 - loss: 1.7099\n",
            "Epoch 39/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.8695 - loss: 1.5816\n",
            "Epoch 40/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.8533 - loss: 1.4552\n",
            "Epoch 41/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8785 - loss: 1.3562\n",
            "Epoch 42/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8748 - loss: 1.3047\n",
            "Epoch 43/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9064 - loss: 1.1748\n",
            "Epoch 44/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9211 - loss: 1.1080\n",
            "Epoch 45/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9058 - loss: 1.0287\n",
            "Epoch 46/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9333 - loss: 0.9243\n",
            "Epoch 47/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9604 - loss: 0.8102\n",
            "Epoch 48/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9403 - loss: 0.7557\n",
            "Epoch 49/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9526 - loss: 0.7287\n",
            "Epoch 50/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9560 - loss: 0.6631\n",
            "Epoch 51/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9462 - loss: 0.6327\n",
            "Epoch 52/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9669 - loss: 0.5748\n",
            "Epoch 53/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9643 - loss: 0.6281\n",
            "Epoch 54/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9722 - loss: 0.5450\n",
            "Epoch 55/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9830 - loss: 0.4907\n",
            "Epoch 56/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9842 - loss: 0.4463\n",
            "Epoch 57/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9905 - loss: 0.4321\n",
            "Epoch 58/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9936 - loss: 0.3613\n",
            "Epoch 59/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9964 - loss: 0.3503\n",
            "Epoch 60/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9964 - loss: 0.3380\n",
            "Epoch 61/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9960 - loss: 0.3116\n",
            "Epoch 62/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9962 - loss: 0.3229\n",
            "Epoch 63/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9922 - loss: 0.2965\n",
            "Epoch 64/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9967 - loss: 0.2712\n",
            "Epoch 65/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9974 - loss: 0.2457\n",
            "Epoch 66/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9964 - loss: 0.2393\n",
            "Epoch 67/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9969 - loss: 0.2229\n",
            "Epoch 68/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2275\n",
            "Epoch 69/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9989 - loss: 0.2072\n",
            "Epoch 70/70\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9991 - loss: 0.2031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f8edb8d5f50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(seed_text, next_words=3):\n",
        "    for _ in range(next_words):  # fixed variable name from 'next_word' to 'next_words'\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1)\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted_word_index = np.argmax(predicted, axis=-1)[0]\n",
        "        predicted_word = tokenizer.index_word[predicted_word_index]\n",
        "        seed_text += \" \" + predicted_word\n",
        "\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "HmzG3DRZVE7R"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_word(\"I am a data scientist and noise dimensionality and noise dimensionality reduction and simplifies data without data\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y54JkkGZ9hB",
        "outputId": "374ab7fe-5449-4117-832e-54712fa87e2f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a data scientist and noise dimensionality and noise dimensionality reduction and simplifies data without data without losing insights\n"
          ]
        }
      ]
    }
  ]
}